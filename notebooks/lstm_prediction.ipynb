{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate multi-step vector-output stacked lstm example\n",
    "from numpy import array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(yhat, test_y, forecasting_horizon):\n",
    "    rmse = mean_squared_error(yhat, test_y) ** 0.5\n",
    "    if forecasting_horizon > 1:\n",
    "        explained_variance = r2_score(test_y, yhat, multioutput = \"variance_weighted\")\n",
    "    else:\n",
    "        explained_variance = 1/abs(rmse)\n",
    "    return rmse, explained_variance\n",
    "\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences_multivariate(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix - 1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(dataset_location, predictor, forecasting_horizon, cfg, exp_id):\n",
    "    df = pd.read_csv(dataset_location)\n",
    "    raw_seq = list(df[predictor].values)\n",
    "    min_raw_seq, ptp_raw_seq = np.min(raw_seq), np.ptp(raw_seq)\n",
    "    raw_seq = (raw_seq - np.min(raw_seq)) / np.ptp(raw_seq)\n",
    "    df[predictor] = raw_seq\n",
    "\n",
    "    # choose a number of time steps\n",
    "    n_steps_in, n_steps_out = cfg['n_steps_in'], forecasting_horizon\n",
    "    # split into samples\n",
    "    X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(cfg['hidden_layer_1_neurons'], activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(cfg['hidden_layer_2_neurons'], activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # # define model\n",
    "    # model = Sequential()\n",
    "    # model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "    # model.add(RepeatVector(n_steps_out))\n",
    "    # model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    # model.add(TimeDistributed(Dense(1)))\n",
    "    # model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # model = Sequential()\n",
    "    # model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "    # model.add(Conv1D(filters=128, kernel_size=5, padding='causal', activation='relu', input_shape=[None, 1]))\n",
    "    # model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    # model.add(TimeDistributed(Dense(1)))\n",
    "    # model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=20, verbose=1)\n",
    "\n",
    "    # model.save('models/lstm_model.h5')\n",
    "\n",
    "    import os\n",
    "\n",
    "    filename = \"models/\" + exp_id + \"/lstm_model/\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    model.save_weights(\"models/\" + exp_id + \"/lstm_model/model_weights.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    import json\n",
    "\n",
    "    config = cfg\n",
    "    config['forecasting_horizon'] = forecasting_horizon\n",
    "    config['min_raw_seq'] = min_raw_seq\n",
    "    config['ptp_raw_seq'] = ptp_raw_seq\n",
    "\n",
    "    with open(\"models/\" + exp_id + '/lstm_model/config.json', 'w') as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "    # demonstrate prediction\n",
    "    x_input = X[-1]\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "    rmse, r2 = calculate_metrics(yhat[0], df[predictor].values[-forecasting_horizon:], forecasting_horizon)\n",
    "\n",
    "    return r2, rmse, df[predictor].values[-forecasting_horizon:], yhat\n",
    "\n",
    "\n",
    "\n",
    "def multivariate_lstm_model(dataset_location, predictor, selected_features, forecasting_horizon, cfg):\n",
    "    df = pd.read_csv(dataset_location)\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    cols.remove(predictor)\n",
    "\n",
    "    col_arr = [df[col].values for col in selected_features] + [df[predictor].values]\n",
    "    raw_seq = np.stack(col_arr, axis=1)\n",
    "\n",
    "    # choose a number of time steps\n",
    "    n_steps_in, n_steps_out = cfg['n_steps_in'], forecasting_horizon\n",
    "    # split into samples\n",
    "    X, y = split_sequences_multivariate(raw_seq, n_steps_in, n_steps_out)\n",
    "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "    n_features = X.shape[2]\n",
    "\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(cfg['hidden_layer_1_neurons'], activation='relu', return_sequences=True,\n",
    "                   input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(cfg['hidden_layer_2_neurons'], activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=5, verbose=1)\n",
    "\n",
    "    # demonstrate prediction\n",
    "    x_input = X[-1]\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "    rmse, r2 = calculate_metrics(yhat[0], df[predictor].values[-forecasting_horizon:], forecasting_horizon)\n",
    "    print(rmse, r2)\n",
    "    # x = input('press to continue')\n",
    "\n",
    "    return 1/rmse, rmse, df[predictor].values[-forecasting_horizon:], yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../datasets/daily-min-temperatures-australia.csv')\n",
    "dataset_location = '../datasets/daily-min-temperatures-australia.csv'\n",
    "predictor = 'Temp'\n",
    "\n",
    "df = pd.read_csv(dataset_location)\n",
    "raw_seq = list(df[predictor].values)\n",
    "min_raw_seq, ptp_raw_seq = np.min(raw_seq), np.ptp(raw_seq)\n",
    "raw_seq = (raw_seq - np.min(raw_seq)) / np.ptp(raw_seq)\n",
    "df[predictor] = raw_seq\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 20, 49\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
